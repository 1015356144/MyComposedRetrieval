# aug/caption_generator.py
import os
import time
import json
import shutil
import traceback
import torch
import torch.distributed as dist
from src.utils import print_rank
from .validators import CaptionValidator
from .batchers import CaptionBatcher
from src.utils.path_utils import get_full_image_path  # âœ… NEW: ç»Ÿä¸€è·¯å¾„è§£æ


class CaptionGenerator:
    """
    åˆ†å¸ƒå¼ / å•å¡ caption å¢å¼ºç”Ÿæˆå™¨
    - é€»è¾‘ä¿æŒä¸åŸå§‹å¤§æ–‡ä»¶ä¸€è‡´ï¼Œä»…æ‹†åˆ†ä¸ºæ¨¡å—åŒ–å®ç°
    - âœ… æ–°å¢ï¼šæŒ‰ CIRR çš„ image_base_dir + image_splits è§„èŒƒåŒ–æ ·æœ¬è·¯å¾„
    """

    def __init__(
        self,
        foundation_model,
        model_args,
        experiment_dir,
        iteration_round,
        prepare_fns,
        generate_fns,
        # ===== NEW: ä¸ºè·¯å¾„è§„èŒƒåŒ–æä¾›ä¸Šä¸‹æ–‡ =====
        image_base_dir: str = "",
        image_splits: dict | None = None,
    ):
        """
        Args:
            foundation_model: åº•å±‚ç”Ÿæˆæ¨¡å‹ï¼ˆå¸¦ .processor ä¸ .generateï¼‰
            model_args: å« foundation_model_backbone ç­‰å­—æ®µ
            experiment_dir: å®éªŒç›®å½•ï¼ˆç”¨äºç¼“å­˜ / åŒæ­¥è½ç›˜ï¼‰
            iteration_round: å½“å‰è¿­ä»£è½®æ¬¡ï¼ˆç”Ÿæˆå†™å…¥ä¸‹ä¸€è½®ç¼–å·çš„æ–‡ä»¶ï¼‰
            prepare_fns: dict, {"qwen": fn, "llava": fn, "generic": fn}
            generate_fns: dict, {"qwen": fn, "llava": fn, "generic": fn}
            image_base_dir: æ•°æ®é›†å›¾ç‰‡æ ¹ç›®å½•ï¼ˆå¦‚ /path/to/CIRRï¼‰
            image_splits: æ˜ å°„ {æ ·æœ¬IDæˆ–ç›¸å¯¹é”® -> ç›¸å¯¹è·¯å¾„}ï¼Œç”¨äºæŠŠé”®è½¬æ¢ä¸ºè·¯å¾„
        """
        self.foundation_model = foundation_model
        self.model_args = model_args
        self.experiment_dir = experiment_dir
        self.iteration_round = iteration_round
        self.augmented_samples = []

        # ä¾èµ– batchers å’Œ validators
        self.batcher = CaptionBatcher(foundation_model, model_args, prepare_fns, generate_fns)
        self.validator = CaptionValidator()

        # ===== NEW: è·¯å¾„ä¸Šä¸‹æ–‡ =====
        self.image_base_dir = image_base_dir or ""
        self.image_splits = image_splits or {}

    # ===== NEW: ç»Ÿä¸€æŠŠ {ref/target/hn} ä¸‰ç±»è·¯å¾„è§„èŒƒåˆ°ç»å¯¹è·¯å¾„ =====
    def _resolve_image_path(self, p: str) -> str:
        """
        - è‹¥ p æ˜¯ç»å¯¹è·¯å¾„ï¼šåŸæ ·è¿”å›
        - è‹¥ p æ˜¯ splits çš„é”®ï¼šå…ˆæ˜ å°„ä¸ºç›¸å¯¹è·¯å¾„ï¼Œå†æ‹¼ base_dir
        - å¦åˆ™ï¼šæŒ‰ç›¸å¯¹è·¯å¾„å¤„ç†å¹¶æ‹¼ base_dir
        """
        if not isinstance(p, str) or p == "":
            return p
        if os.path.isabs(p):
            return p
        mapped = self.image_splits.get(p, p)
        return get_full_image_path(mapped, self.image_base_dir)

    def _normalize_item_paths(self, item: dict) -> dict:
        out = dict(item)
        if "reference_image" in out:
            out["reference_image"] = self._resolve_image_path(out["reference_image"])
        if "target_image" in out and out["target_image"]:
            out["target_image"] = self._resolve_image_path(out["target_image"])
        if "hard_negative_image" in out and out["hard_negative_image"]:
            out["hard_negative_image"] = self._resolve_image_path(out["hard_negative_image"])
        return out

    # =========================
    #         å•å¡é€»è¾‘
    # =========================
    def generate_augmented_captions(self, hard_negatives):
        """å•å¡å¢å¼º caption ç”Ÿæˆ"""
        if not self.foundation_model:
            print_rank("No foundation model, skipping caption generation")
            return []

        next_iter = self.iteration_round + 1
        aug_file = os.path.join(self.experiment_dir, f"augmented_samples_iter_{next_iter}.json")

        # è¯»ç¼“å­˜
        if os.path.exists(aug_file):
            print_rank(f"Loading existing augmented samples from {aug_file}")
            try:
                with open(aug_file, "r") as f:
                    saved = json.load(f)
                samples = saved.get("samples", [])
                samples = self.validator.filter_valid_samples(samples)
                self.augmented_samples = samples
                return samples
            except Exception as e:
                print_rank(f"Error loading augmented samples: {e}, regenerating...")

        print_rank(f"Generating augmented captions for {len(hard_negatives)} hard negatives")
        augmented_samples = []
        batch_size = 4
        total_batches = (len(hard_negatives) + batch_size - 1) // batch_size
        start_time = time.time()

        for i in range(0, len(hard_negatives), batch_size):
            batch_idx = i // batch_size + 1
            batch = hard_negatives[i:i+batch_size]
            # ETA
            if batch_idx > 1:
                elapsed = time.time() - start_time
                avg_tpb = elapsed / (batch_idx - 1)
                remain = total_batches - batch_idx + 1
                eta = f"ETA {int((avg_tpb*remain)//60):02d}:{int((avg_tpb*remain)%60):02d}"
            else:
                eta = "ETA calculating..."

            print_rank(f"Processing batch {batch_idx}/{total_batches} ({len(batch)}) - {eta}")
            try:
                batch_start = time.time()
                batch_aug = self._generate_caption_batch(batch)
                augmented_samples.extend(batch_aug)
                print_rank(f"Batch {batch_idx}/{total_batches} done in {time.time()-batch_start:.1f}s, +{len(batch_aug)}")
            except Exception as e:
                print_rank(f"Error in batch {batch_idx}: {e}")
                continue

        augmented_samples = self.validator.filter_valid_samples(augmented_samples)
        self._save_augmented_samples(augmented_samples)
        total_time = time.time() - start_time
        print_rank(f"âœ… Generated {len(augmented_samples)} samples in {total_time:.1f}s")
        return augmented_samples

    def _generate_caption_batch(self, hard_negatives_batch):
        """æ‰¹é‡ç”Ÿæˆ captionï¼ˆä¸å•å¡/å¤šå¡å¤ç”¨ï¼‰"""
        from PIL import Image

        augmented = []
        foundation_processor = getattr(self.foundation_model, "processor", None)
        if foundation_processor is None:
            print_rank("Foundation model has no processor")
            return []

        device = next(self.foundation_model.parameters()).device
        ref_images, tgt_images, texts, meta = [], [], [], []

        # æ‰“åŒ…
        for hard_neg in hard_negatives_batch:
            try:
                norm_item = self._normalize_item_paths(hard_neg)

                ref_path = norm_item["reference_image"]
                tgt_path = norm_item.get("hard_negative_image", norm_item.get("target_image"))

                ref_img = Image.open(ref_path).convert("RGB")
                tgt_img = Image.open(tgt_path).convert("RGB")

                ref_images.append(ref_img)
                tgt_images.append(tgt_img)
                texts.append(norm_item["modification_text"])
                meta.append(norm_item)  # âœ… åç»­å†™å›æ—¶ä½¿ç”¨è§„èŒƒåŒ–åçš„ç»å¯¹è·¯å¾„
            except Exception as e:
                print_rank(f"Error preparing sample: {e}")

        # ç”Ÿæˆ
        if ref_images:
            generated_texts = self.batcher.generate_batch(
                ref_images, tgt_images, texts, foundation_processor, device
            )
            for hard_neg, gen_text in zip(meta, generated_texts):
                if gen_text and self.validator.is_valid(gen_text):
                    augmented.append({
                        "reference_image": hard_neg["reference_image"],
                        "modification_text": gen_text,
                        "target_image": hard_neg.get("hard_negative_image", hard_neg.get("target_image")),
                        "original_mod_text": hard_neg["modification_text"],
                        "is_augmented": True,
                        "hard_negative_rank": hard_neg.get("rank_position"),
                        "similarity_score": hard_neg.get("similarity_score")
                    })
        return augmented

    # =========================
    #        åˆ†å¸ƒå¼é€»è¾‘
    # =========================
    def generate_augmented_captions_distributed(self, hard_negatives):
        """
        å¤šå¡åˆ†å¸ƒå¼ caption ç”Ÿæˆï¼ˆæ–‡ä»¶å¼åŒæ­¥ä¸èšåˆï¼‰
        å®Œæ•´å¤åˆ»ä½ åŸå§‹å®ç°çš„è¡Œä¸ºï¼Œä½†æ¨¡å—åŒ–å¹¶å¤ç”¨éªŒè¯/ä¿å­˜å‡½æ•°ã€‚
        """
        if not self.foundation_model:
            print_rank("No foundation model provided, skipping caption generation")
            return []

        next_iter = self.iteration_round + 1
        final_aug_file = os.path.join(self.experiment_dir, f"augmented_samples_iter_{next_iter}.json")

        # è¯»ç¼“å­˜ï¼šæ‰€æœ‰ rank éƒ½å°è¯•ç›´æ¥è¯»
        if os.path.exists(final_aug_file):
            print_rank(f"Loading existing augmented samples from {final_aug_file}")
            try:
                with open(final_aug_file, "r") as f:
                    saved = json.load(f)
                samples = self.validator.filter_valid_samples(saved.get("samples", []))
                self.augmented_samples = samples
                return samples
            except Exception as e:
                print_rank(f"Error loading augmented samples: {e}, regenerating...")

        # æ— åˆ†å¸ƒå¼åˆ™é€€åŒ–ä¸ºå•å¡
        if not dist.is_initialized():
            return self.generate_augmented_captions(hard_negatives)

        world_size = dist.get_world_size()
        rank = dist.get_rank()
        print_rank(f"Starting distributed caption generation for {len(hard_negatives)} samples using {world_size} GPUs")

        # ä»»åŠ¡åˆ‡åˆ†
        total = len(hard_negatives)
        per_gpu = (total + world_size - 1) // world_size
        start_idx = rank * per_gpu
        end_idx = min(start_idx + per_gpu, total)
        local_list = hard_negatives[start_idx:end_idx]
        print_rank(f"GPU {rank}: Assigned {len(local_list)} samples [{start_idx}, {end_idx})")

        # è®¾å¤‡æ”¾ç½®
        device = f"cuda:{rank}" if torch.cuda.is_available() else "cpu"
        if hasattr(self.foundation_model, "to"):
            self.foundation_model = self.foundation_model.to(device)

        # æœ¬åœ°ç”Ÿæˆ
        local_aug = []
        if local_list:
            batch_size = 4
            total_batches = (len(local_list) + batch_size - 1) // batch_size
            start_time = time.time()
            for i in range(0, len(local_list), batch_size):
                bidx = i // batch_size + 1
                batch = local_list[i:i+batch_size]

                # é™ä½è¾“å‡ºå™ªå£°ï¼šrank0 å…¨æ‰“ï¼Œå…¶ä»–æ¯ 5 ä¸ªæ‰¹æ¬¡æ‰“ä¸€æ¬¡
                if bidx % 5 == 1 or rank == 0:
                    if bidx > 1:
                        elapsed = time.time() - start_time
                        avg_tpb = elapsed / (bidx - 1)
                        remain = total_batches - bidx + 1
                        eta = f"ETA {int((avg_tpb*remain)//60):02d}:{int((avg_tpb*remain)%60):02d}"
                    else:
                        eta = "ETA calculating..."
                    print_rank(f"GPU {rank}: ğŸ”„ Batch {bidx}/{total_batches} ({len(batch)}) - {eta}")

                try:
                    t0 = time.time()
                    batch_aug = self._generate_caption_batch(batch)
                    local_aug.extend(batch_aug)
                    if bidx % 5 == 0 or rank == 0 or bidx == total_batches:
                        print_rank(f"GPU {rank}: âœ… Batch {bidx}/{total_batches} in {time.time()-t0:.1f}s, +{len(batch_aug)}")
                except Exception as e:
                    print_rank(f"âŒ GPU {rank}: Error in batch {bidx}: {e}")
                    print_rank(traceback.format_exc())
        else:
            print_rank(f"GPU {rank}: No local samples, skip generation")

        print_rank(f"GPU {rank}: ğŸ¯ Local generation done: {len(local_aug)} samples")

        # ============ æ–‡ä»¶å¼åŒæ­¥ï¼šé˜¶æ®µ 1ï¼ˆå®Œæˆæ ‡è®°ï¼‰ ============
        sync_dir = os.path.join(self.experiment_dir, "sync_caption_gen")
        if rank == 0:
            os.makedirs(sync_dir, exist_ok=True)
            print_rank(f"GPU 0: Created sync dir {sync_dir}")

        _wait_dir(sync_dir, rank, max_wait_s=36000)
        completion_flag = os.path.join(sync_dir, f"gpu_{rank}_completed.txt")
        try:
            with open(completion_flag, "w") as f:
                f.write(f"GPU {rank} completed {len(local_aug)} samples at {time.time()}")
            print_rank(f"GPU {rank}: Wrote completion flag: {completion_flag}")
        except Exception as e:
            print_rank(f"GPU {rank}: Error writing completion flag: {e}")
            os.makedirs(sync_dir, exist_ok=True)
            with open(completion_flag, "w") as f:
                f.write(f"GPU {rank} completed {len(local_aug)} samples at {time.time()}")
            print_rank(f"GPU {rank}: Retried flag ok")

        # ç­‰å¾…æ‰€æœ‰ rank å®Œæˆ
        print_rank(f"GPU {rank}: Waiting all completion flags")
        _wait_all_flags(sync_dir, world_size, rank, max_wait_s=36000)

        # ============ æ–‡ä»¶å¼åŒæ­¥ï¼šé˜¶æ®µ 2ï¼ˆå„è‡ªå†™ç»“æœï¼‰ ============
        tmp_dir = os.path.join(self.experiment_dir, "temp_caption_results")
        if rank == 0:
            os.makedirs(tmp_dir, exist_ok=True)
            print_rank(f"GPU 0: Created tmp dir {tmp_dir}")
        _wait_dir(tmp_dir, rank, max_wait_s=36000)

        # æœ¬åœ°å†™æ–‡ä»¶
        local_file = os.path.join(tmp_dir, f"gpu_{rank}_samples.json")
        try:
            with open(local_file, "w") as f:
                json.dump({
                    "rank": rank,
                    "samples": local_aug,
                    "count": len(local_aug),
                    "timestamp": time.time()
                }, f, indent=2)
            print_rank(f"GPU {rank}: Saved {len(local_aug)} to {local_file}")
        except Exception as e:
            print_rank(f"GPU {rank}: Error saving local file: {e}")

        # ç­‰å¾…æ‰€æœ‰æœ¬åœ°æ–‡ä»¶ ready
        print_rank(f"GPU {rank}: Waiting all gpu files")
        _wait_all_files(tmp_dir, world_size, rank, max_wait_s=36000)

        # ============ ä¸»è¿›ç¨‹èšåˆ ============
        if rank == 0:
            all_aug = [local_aug]  # include rank0
            for r in range(1, world_size):
                fp = os.path.join(tmp_dir, f"gpu_{r}_samples.json")
                try:
                    if os.path.exists(fp):
                        with open(fp, "r") as f:
                            data = json.load(f)
                        samples = data.get("samples", [])
                        all_aug.append(samples)
                        print_rank(f"GPU 0: Loaded {len(samples)} from GPU {r}")
                    else:
                        print_rank(f"GPU 0: Missing file for GPU {r}, append []")
                        all_aug.append([])
                except Exception as e:
                    print_rank(f"GPU 0: Error reading GPU {r} file: {e}")
                    all_aug.append([])

            merged = []
            for chunk in all_aug:
                if chunk and isinstance(chunk, list):
                    merged.extend(chunk)
                    print_rank(f"GPU 0: merge chunk +{len(chunk)}")

            # è¿‡æ»¤æ— æ•ˆ
            print_rank(f"GPU 0: Filtering {len(merged)} samples")
            merged = self.validator.filter_valid_samples(merged)

            # ä¿å­˜æœ€ç»ˆæ–‡ä»¶
            self._save_augmented_samples(merged)
            print_rank(f"âœ… GPU 0: Saved {len(merged)} merged samples")

            # æ¸…ç†
            try:
                shutil.rmtree(tmp_dir)
                print_rank(f"GPU 0: Cleaned tmp dir {tmp_dir}")
                if os.path.exists(sync_dir):
                    shutil.rmtree(sync_dir)
                    print_rank(f"GPU 0: Cleaned sync dir {sync_dir}")
            except Exception as e:
                print_rank(f"GPU 0: Cleanup warning: {e}")

        # ============ å…¨éƒ¨ rank ç­‰å¾…æœ€ç»ˆæ–‡ä»¶ ============
        print_rank(f"GPU {rank}: Waiting final file")
        _wait_file(final_aug_file, rank, max_wait_s=36000)

        # å…¨éƒ¨ rank è¯»æœ€ç»ˆæ–‡ä»¶ï¼ˆä¿æŒä¸€è‡´ï¼‰
        final_aug = []
        if os.path.exists(final_aug_file):
            try:
                with open(final_aug_file, "r") as f:
                    saved = json.load(f)
                final_aug = self.validator.filter_valid_samples(saved.get("samples", []))
                print_rank(f"GPU {rank}: Final loaded {len(final_aug)} samples")
            except Exception as e:
                print_rank(f"GPU {rank}: Error loading final file: {e}")
        else:
            print_rank(f"GPU {rank}: Final file not found")

        self.augmented_samples = final_aug
        print_rank(f"GPU {rank}: ğŸ¯ Distributed caption generation completed: {len(final_aug)}")
        return final_aug

    # =========================
    #        å…¬å…±æ–¹æ³•
    # =========================
    def _save_augmented_samples(self, samples):
        """ä¿å­˜å¢å¼ºæ ·æœ¬ï¼ˆå†™ä¸‹ä¸€è½®ç¼–å·ï¼‰"""
        next_iter = self.iteration_round + 1
        out_file = os.path.join(self.experiment_dir, f"augmented_samples_iter_{next_iter}.json")
        # é™„å¸¦åŸºç¡€ç»Ÿè®¡
        summary = {
            "total_samples": len(samples),
            "generation_timestamp": time.time(),
            "iteration_round": next_iter,
            "sample_statistics": {
                "avg_original_length": (sum(len(s.get("original_mod_text", "")) for s in samples) / len(samples)) if samples else 0,
                "avg_generated_length": (sum(len(s.get("modification_text", "")) for s in samples) / len(samples)) if samples else 0,
                "unique_reference_images": len(set(s.get("reference_image", "") for s in samples)),
                "unique_target_images": len(set(s.get("target_image", "") for s in samples)),
            },
            "samples": samples
        }
        # è½ç›˜å¹¶å¼ºåˆ¶ flush
        with open(out_file, "w") as f:
            json.dump(summary, f, indent=2)
            f.flush()
            os.fsync(f.fileno())
        print_rank(f"âœ… Saved {len(samples)} samples to {out_file}")


# --------------------------
# è¾…åŠ©å‡½æ•°ï¼ˆåˆ†å¸ƒå¼è½®è¯¢ï¼‰
# --------------------------
def _wait_dir(path, rank, max_wait_s=36000):
    """ç­‰å¾…ç›®å½•å‡ºç°ï¼ˆæ–‡ä»¶è½®è¯¢ï¼‰ï¼Œé¿å… barrier è§¦å‘ NCCL çœ‹é—¨ç‹—"""
    waited = 0
    while not os.path.exists(path) and waited < max_wait_s:
        time.sleep(1)
        waited += 1
        if waited % 10 == 0:
            print_rank(f"GPU {rank}: Waiting dir {path}... {waited}s")
    if not os.path.exists(path):
        print_rank(f"GPU {rank}: âŒ Dir wait timeout, try make locally: {path}")
        os.makedirs(path, exist_ok=True)


def _wait_all_flags(sync_dir, world_size, rank, max_wait_s=36000):
    """ç­‰å¾…æ‰€æœ‰ GPU çš„å®Œæˆæ ‡è®°"""
    start = time.time()
    while time.time() - start < max_wait_s:
        all_ok = True
        for r in range(world_size):
            if not os.path.exists(os.path.join(sync_dir, f"gpu_{r}_completed.txt")):
                all_ok = False
                break
        if all_ok:
            print_rank(f"GPU {rank}: âœ… All completion flags ready")
            return
        time.sleep(5)
        elapsed = int(time.time() - start)
        if elapsed % 120 == 0:
            done = [r for r in range(world_size)
                    if os.path.exists(os.path.join(sync_dir, f"gpu_{r}_completed.txt"))]
            print_rank(f"GPU {rank}: Waiting flags... done={done}, elapsed={elapsed}s")
    print_rank(f"GPU {rank}: âŒ Timeout waiting completion flags")


def _wait_all_files(tmp_dir, world_size, rank, max_wait_s=36000):
    """ç­‰å¾…æ‰€æœ‰ GPU å†™å‡ºä¸´æ—¶ç»“æœæ–‡ä»¶"""
    start = time.time()
    while time.time() - start < max_wait_s:
        all_ok = True
        missing = []
        for r in range(world_size):
            fp = os.path.join(tmp_dir, f"gpu_{r}_samples.json")
            if not os.path.exists(fp):
                all_ok = False
                missing.append(r)
        if all_ok:
            print_rank(f"GPU {rank}: âœ… All GPU files ready")
            return
        time.sleep(2)
        elapsed = int(time.time() - start)
        if elapsed % 60 == 0 and elapsed > 0:
            print_rank(f"GPU {rank}: Waiting files... missing={missing} elapsed={elapsed}s")
    print_rank(f"GPU {rank}: âŒ Timeout waiting gpu files")


def _wait_file(path, rank, max_wait_s=36000):
    """ç­‰å¾…æœ€ç»ˆåˆå¹¶æ–‡ä»¶"""
    start = time.time()
    while time.time() - start < max_wait_s:
        if os.path.exists(path):
            print_rank(f"GPU {rank}: âœ… Final file ready")
            return
        time.sleep(2)
        elapsed = int(time.time() - start)
        if elapsed % 10 == 0 and elapsed > 0:
            print_rank(f"GPU {rank}: Waiting final file... {elapsed}s")
    print_rank(f"GPU {rank}: âŒ Timeout waiting final file {path}")
