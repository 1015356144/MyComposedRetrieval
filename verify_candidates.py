#!/usr/bin/env python3
"""
Test script to verify the improved retrieval candidate set construction
"""
import json
import os

def verify_retrieval_candidates():
    """Verify that we're using the complete retrieval candidate set"""
    
    print("ğŸ” Verifying CIRR Retrieval Candidate Set Construction")
    print("=" * 60)
    
    # Paths from your config
    captions_file = "/home/guohaiyun/yty_data/CIRR/cirr/captions/cap.rc2.train.json"
    image_splits_file = "/home/guohaiyun/yty_data/CIRR/cirr/image_splits/split.rc2.train.json"
    
    # Load captions (training samples)
    with open(captions_file, 'r') as f:
        annotations = json.load(f)
    
    # Load image splits (ALL candidate images)
    with open(image_splits_file, 'r') as f:
        image_splits = json.load(f)
    
    print(f"ğŸ“Š Dataset Statistics:")
    print(f"   â€¢ Training samples: {len(annotations)}")
    print(f"   â€¢ Total candidate images: {len(image_splits)}")
    print()
    
    # Analyze coverage
    unique_refs = set()
    unique_targets = set()
    
    for ann in annotations:
        unique_refs.add(ann['reference'])
        unique_targets.add(ann['target_hard'])
    
    print(f"ğŸ“ˆ Sample Analysis:")
    print(f"   â€¢ Unique reference images: {len(unique_refs)}")
    print(f"   â€¢ Unique target images: {len(unique_targets)}")
    print(f"   â€¢ All unique images in samples: {len(unique_refs | unique_targets)}")
    print()
    
    # Check coverage in image_splits
    refs_in_splits = sum(1 for ref in unique_refs if ref in image_splits)
    targets_in_splits = sum(1 for target in unique_targets if target in image_splits)
    
    print(f"âœ… Coverage Analysis:")
    print(f"   â€¢ Reference images in candidate set: {refs_in_splits}/{len(unique_refs)} ({100*refs_in_splits/len(unique_refs):.1f}%)")
    print(f"   â€¢ Target images in candidate set: {targets_in_splits}/{len(unique_targets)} ({100*targets_in_splits/len(unique_targets):.1f}%)")
    print()
    
    print(f"ğŸ¯ Hard Negative Mining Improvement:")
    print(f"   â€¢ OLD approach: Limited to ~200 candidates")
    print(f"   â€¢ NEW approach: Uses ALL {len(image_splits)} candidates")
    print(f"   â€¢ Improvement factor: {len(image_splits)/200:.1f}x more candidates!")
    print()
    
    print(f"ğŸ’¡ Key Insights:")
    print(f"   â€¢ image_splits_file contains the COMPLETE retrieval database")
    print(f"   â€¢ This matches CIRR evaluation protocol requirements")
    print(f"   â€¢ Hard negatives will now be selected from the full candidate set")
    print(f"   â€¢ This should significantly improve training quality")
    print()
    
    # Sample a few image paths
    sample_names = list(image_splits.keys())[:5]
    print(f"ğŸ”— Sample Image Mappings:")
    for name in sample_names:
        print(f"   â€¢ {name} â†’ {image_splits[name]}")

if __name__ == "__main__":
    verify_retrieval_candidates()
