# NHR-Edit Dataset Configuration for Iterative Training - PRODUCTION MODE

NHR_EDIT:
    dataset_parser: IterativeNHREditDataset
    dataset_name: NHR-Edit  # local NHR-Edit data
    dataset_split: train
    data_dir: /home/share/yty_data/iitolstykh/NHR-Edit  # local data directory
    image_base_dir: /home/share/yty_data/iitolstykh/NHR-Edit/train  # base directory for images (train subdirectory)
    metadata_file: train/metadata.jsonl  # metadata file relative to data_dir
    num_sample_per_subset: -1  # Use all samples for production
    weight: 1.0
    
    # Iterative training specific configs - PRODUCTION
    max_iterations: 2  # Full iterative training cycles
    hard_neg_collection_freq: 1
    hard_neg_top_k: 10
    caption_generation_batch_size: 16  # Increased for 8-GPU production
    
    # Production mode settings - ENABLED for production training
    # ðŸ”„ NEW INDEPENDENT TRAINING STRATEGY:
    # Each iteration resets optimizer/scheduler for independent LR schedule
    # - steps_per_iteration: 2800 steps per iteration (â‰ˆ3 epochs for 358,463 samples with 8Ã—48 batch size)
    # - Dataset: 358,463 samples, Batch: 8Ã—48=384, Steps per epoch: â‰ˆ933, 3 epochs â‰ˆ 2800 steps
    # - warmup_steps: 280 (10% of steps_per_iteration, set in training script)
    # - This ensures fresh learning rate for each iteration's hard negative learning
    fast_mode: false  # Disable fast mode for production
    steps_per_iteration: 2800  # Steps per iteration (â‰ˆ3 epochs, each iteration trains independently)
    production_save_steps: 500   # Save every 500 steps
    production_eval_steps: 1000  # Evaluate every 1000 steps
    production_logging_steps: 50  # Log every 50 steps
    
    # Fast mode settings - DISABLED for production
    # fast_mode: true  # Quick testing mode
    # fast_mode_max_samples: 200  # Limit hard negative samples for quick testing
    # fast_mode_retrieval_db_size: 100  # Small retrieval database for testing
    # fast_mode_max_steps: 20  # Minimal steps for testing (per iteration)
    # fast_mode_save_steps: 10  # Frequent saves for debugging
    # fast_mode_eval_steps: 15  # Quick evaluation
    # fast_mode_logging_steps: 2  # Verbose logging for debugging
    
    # Foundation model for caption generation - Qwen2VL-7B
    foundation_model_name: "/home/guohaiyun/yangtianyu/CPRCIR/checkpoints/hf_models/Qwen2-VL-7B-Instruct"
    foundation_model_temperature: 0.7
    foundation_model_max_length: 128  # Increased for better quality